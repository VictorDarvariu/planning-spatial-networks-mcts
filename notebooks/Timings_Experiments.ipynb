{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "# if platform.system() == 'Darwin':\n",
    "#     matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from relnet.utils.general_utils import *\n",
    "from relnet.agent.baseline.baseline_agent import *\n",
    "from relnet.agent.mcts.mcts_agent import *\n",
    "\n",
    "from relnet.evaluation.storage import EvaluationStorage\n",
    "from relnet.evaluation.experiment_conditions import *\n",
    "from relnet.evaluation.file_paths import FilePaths\n",
    "from relnet.evaluation.experiment_conditions import *\n",
    "from relnet.visualization import *\n",
    "\n",
    "\n",
    "algorithm_class = 'planning'\n",
    "\n",
    "full_g_sizes = [25, 50, 75, 100, 125, 150, 175, 200]\n",
    "g_sizes = [25, 50, 75, 100, 125, 150, 175, 200]\n",
    "# g_sizes = [100]\n",
    "exp_ids = [f'timingsv2_kh_{g_size}' for g_size in g_sizes]\n",
    "exp_ids\n",
    "\n",
    "\n",
    "\n",
    "storage = EvaluationStorage()\n",
    "fp = FilePaths('/experiment_data', 'aggregate', setup_directories=True)\n",
    "\n",
    "\n",
    "considered_agents_fig = [GreedyAgent.algorithm_name,\n",
    "                         CostSensitiveGreedyAgent.algorithm_name,\n",
    "                         StandardMCTSAgent.algorithm_name,\n",
    "                         SGUCTAgent.algorithm_name\n",
    "                     ]\n",
    "\n",
    "considered_agents_table = [\n",
    "                     RandomAgent.algorithm_name,\n",
    "                     \n",
    "                     GreedyAgent.algorithm_name,\n",
    "                     CostSensitiveGreedyAgent.algorithm_name,\n",
    "                     \n",
    "                           \n",
    "                     LowestDegreeProductAgent.algorithm_name,\n",
    "                     FiedlerVectorAgent.algorithm_name,\n",
    "                     EffectiveResistanceAgent.algorithm_name,\n",
    "                     MinCostAgent.algorithm_name,\n",
    "                     LBHBAgent.algorithm_name,\n",
    "                           \n",
    "                     StandardMCTSAgent.algorithm_name,\n",
    "                     SGUCTAgent.algorithm_name,\n",
    "                     ]\n",
    "\n",
    "\n",
    "algo_display_names = {\n",
    "                     GreedyAgent.algorithm_name: \"Greedy\",\n",
    "                     CostSensitiveGreedyAgent.algorithm_name: \"GreedyCS\",\n",
    "                     StandardMCTSAgent.algorithm_name: \"UCT\",\n",
    "                     SGUCTAgent.algorithm_name: \"SG-UCT\",\n",
    "                     \n",
    "                     RandomAgent.algorithm_name: \"Random\",\n",
    "                     LowestDegreeProductAgent.algorithm_name: \"LDP\",\n",
    "                     FiedlerVectorAgent.algorithm_name: \"FV\",\n",
    "                     EffectiveResistanceAgent.algorithm_name: \"ERes\",\n",
    "                     MinCostAgent.algorithm_name: \"MinCost\",\n",
    "                     LBHBAgent.algorithm_name: \"LBHB\",\n",
    "\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_timings(exp_ids, which_agents):\n",
    "    all_timings = []\n",
    "    for i in range(len(exp_ids)):\n",
    "        g_size = g_sizes[i]\n",
    "        exp_id = exp_ids[i]\n",
    "        \n",
    "        \n",
    "        fp_in = FilePaths('/experiment_data', exp_id, setup_directories=False)\n",
    "        for f in fp_in.timings_dir.iterdir():\n",
    "            if f.is_file():\n",
    "                header_names = ['timestep', 'before_or_after', 'g_list_idx', 'timestamp', 'num_sims']\n",
    "                timings_df = pd.read_csv(f, sep=',', header=None, names=header_names)\n",
    "                \n",
    "                if f.name.startswith(\".\"):\n",
    "                    continue\n",
    "                \n",
    "                fname_parts = str(f.name).split(\"-\")\n",
    "                algo = fname_parts[0]\n",
    "                obj_fun = fname_parts[1]\n",
    "                network_generator = fname_parts[2]\n",
    "                if 'rw' in exp_id:\n",
    "                    g_seed = fname_parts[3]\n",
    "                else:\n",
    "                    g_seed = int(fname_parts[3].split(\"_\")[-1])\n",
    "                \n",
    "                if algo not in which_agents:\n",
    "                    continue\n",
    "                \n",
    "                timings_entry = {}\n",
    "                timings_entry['algo'] = algo_display_names[algo]\n",
    "                timings_entry['obj_fun'] = obj_fun\n",
    "                timings_entry['network_generator'] = network_generator\n",
    "                timings_entry['g_seed'] = g_seed\n",
    "                timings_entry['g_size'] = g_size if 'rw' not in exp_id else -1\n",
    "                \n",
    "                total_ms = (timings_df[['timestamp']].diff().dropna().sum()).iloc[0]\n",
    "                total_sims = (timings_df[['num_sims']].dropna().sum()).iloc[0]\n",
    "                \n",
    "                num_moves = len(timings_df) / 2\n",
    "                \n",
    "                timings_entry['total_ms'] = total_ms\n",
    "                timings_entry['total_s'] = total_ms / 1000\n",
    "                timings_entry['total_sims'] = total_sims\n",
    "                \n",
    "                timings_entry['num_moves'] = num_moves\n",
    "                timings_entry['avg_s_per_move'] = total_ms / num_moves / 1000\n",
    "                timings_entry['avg_sims_per_move'] = total_sims / num_moves\n",
    "\n",
    "                all_timings.append(timings_entry)\n",
    "        \n",
    "\n",
    "    agg_df = pd.DataFrame(all_timings)\n",
    "    agg_df = agg_df.sort_values(by=[\"algo\"], ascending=[True], axis=0)\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_df = fetch_timings(exp_ids, considered_agents_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of SG-UCT in hours for graphs of size 200\n",
    "relevant_entries = timings_df[(timings_df[\"g_size\"] == 200) & (timings_df[\"algo\"] == \"SG-UCT\")]\n",
    "relevant_entries[\"total_s\"].mean() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_funs = [\"global_eff\", \"lcs_targeted\"]\n",
    "obj_funs_display ={\"global_eff\": \"$\\mathcal{F}_{E}$\", \"lcs_targeted\" :\"$\\mathcal{F}_{R}$\"}\n",
    "\n",
    "metrics = [\"total_s\", \"avg_s_per_move\", \"total_sims\", \"avg_sims_per_move\"]\n",
    "metrics_display = [\"Total seconds\", \"Mean seconds per step\", \"Total $\\mathcal{F}$ evaluations\", \"Mean $\\mathcal{F}$ evaluations per step\"]\n",
    "metrics_display_dict = {metrics[i]: metrics_display[i] for i in range(len(metrics))}\n",
    "\n",
    "\n",
    "sns.set(font_scale=8.5)\n",
    "plt.rc('font', family='serif')\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams[\"lines.linewidth\"] = 16\n",
    "mpl.rcParams[\"lines.markersize\"] = 25\n",
    "dims = (2 * 8.26 * len(metrics), 2.25 * 8.26 * len(obj_funs))\n",
    "legend_i, legend_j = 1, 3\n",
    "\n",
    "fig, axes = plt.subplots(len(obj_funs), len(metrics), figsize=dims, squeeze=False, sharey=False)\n",
    "\n",
    "\n",
    "\n",
    "for i, obj_fun in enumerate(obj_funs):\n",
    "    for j, metric in enumerate(metrics):\n",
    "        ax = axes[i][j]\n",
    "\n",
    "        ax.set(yscale=\"log\")\n",
    "        plot_df = timings_df[timings_df[\"obj_fun\"] == obj_fun]\n",
    "        plot_df = plot_df.rename(columns={\"g_size\": \"$N$\", metric: metrics_display[j], \"algo\": \"Algorithm\"})\n",
    "        sns.lineplot(data=plot_df, x=\"$N$\", y=metrics_display[j], hue=\"Algorithm\", ax=ax)\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_xlabel('')\n",
    "\n",
    "        ax.tick_params(axis='x', which='major', labelsize=68)\n",
    "        ax.tick_params(axis='y', which='major', labelsize=80)\n",
    "        #         ax.tick_params(axis='both', which='minor', labelsize=8)\n",
    "        ax.set_xticks(full_g_sizes)\n",
    "        \n",
    "        ax.legend_.remove()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        if i == legend_i and j == legend_j:\n",
    "            legend_ax = ax\n",
    "        \n",
    "legend_ax.legend(handles[1:], labels[1:], loc='lower right', borderaxespad=0.1, fontsize=\"small\")\n",
    "\n",
    "\n",
    "pad = 12.5\n",
    "cols = metrics\n",
    "for ax, col in zip(axes[0], cols):\n",
    "    ax.annotate(f\"{metrics_display_dict[col]}\",\n",
    "                xy=(0.5, 1), xytext=(0, pad),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='small', ha='center', va='baseline')\n",
    "\n",
    "rows = obj_funs\n",
    "for ax, row in zip(axes[:, 0], rows):\n",
    "    ax.annotate(f\"{obj_funs_display[row]}\", xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                rotation=90,\n",
    "                xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='right', va='center',\n",
    "               annotation_clip=False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.5, w_pad=0.1, h_pad=0.5)\n",
    "fig.savefig(fp.figures_dir / \"timings_all.pdf\")\n",
    "# fig.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def format_timing(val_ms):\n",
    "    print(val_ms)\n",
    "    if np.isnan(float(val_ms)):\n",
    "        return \"---\"\n",
    "    \n",
    "    val_seconds = int(val_ms / 1000)\n",
    "    if val_seconds == 0:\n",
    "        timing_string = \"<00:01\"\n",
    "    else:\n",
    "        timing_string = '{:01}:{:02}:{:02}'.format(val_seconds//3600, val_seconds%3600//60, val_seconds%60)\n",
    "    return timing_string\n",
    "\n",
    "rw_timings = fetch_timings([\"timingsv2_rw\"], considered_agents_table)\n",
    "rw_timings['timings_string'] = rw_timings['total_ms'].apply(format_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_timings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwt_pivot = pd.pivot_table(rw_timings, values='timings_string',\n",
    "                   index= ['obj_fun', 'network_generator', 'g_seed'],\n",
    "                   columns=['algo'],\n",
    "                   aggfunc='first')\n",
    "\n",
    "rwt_pivot = rwt_pivot[[algo_display_names[a] for a in considered_agents_table]]\n",
    "\n",
    "rwt_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_write_latex(pivot_table, cols_order, filename):\n",
    "    latex_df = pivot_table.copy()\n",
    "    texfile =  str(fp.figures_dir / filename)\n",
    "    fh = open(texfile, 'w')\n",
    "    table_colformat = f\"ccc|{''.join(['r'] * len(cols_order)) }\"\n",
    "    latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, column_format=table_colformat)\n",
    "    fh.close()\n",
    "\n",
    "    replace_dict = {\n",
    "        r\"reduction\\\\_policy\": r\"$\\phi$\",\n",
    "        r\"sim\\\\_policy\\\\_bias\": r\"$\\\\beta$\",\n",
    "        r\"exp\\\\_name\": r\"Experiment\",\n",
    "        r\"synth\\\\_25\": r\"KH-25\",\n",
    "        r\"synth\\\\_50\": r\"KH-50\",\n",
    "        r\"synth\\\\_75\": r\"KH-75\",\n",
    "        r\"rw\\\\_internet\\\\_topology\": r\"Internet\",\n",
    "        r\"rw\\\\_metro\": r\"Metro\",        \n",
    "        r\"rw\": \"Real-world\",\n",
    "        \n",
    "        r\"C\\\\_p\": r\"$C_p$\",\n",
    "        \n",
    "        r\"SG-UCT\": \"SG-UCT (ours)\",\n",
    "        r\"internet\\\\_topology\": \"Internet\",\n",
    "        r\"metro\": \"Metro\",\n",
    "        r\"graph\\\\_id\": \"Graph\",\n",
    "        r\"g\\\\_seed\": \"Graph\",\n",
    "        \n",
    "        r\"nan±nan\": r\"---\",\n",
    "        r\"NaN\": r\"---\",\n",
    "        r\"nan\": r\"---\",\n",
    "        r\"obj\\\\_fun\": r\"$\\\\mathcal{F}$\",\n",
    "        r\"objective\\\\_function\": r\"$\\\\mathcal{F}$\",\n",
    "        r\"network\\\\_size\" : r\"$|V|$\",\n",
    "        r\"network\\\\_generator\" : r\"$\\\\mathbf{G}$\",\n",
    "        r\"kaiser\\\\_hilgetag\": r\"KH\",\n",
    "        r\"internet\\\\_topology\": r\"Internet\",\n",
    "        r\"metro\": r\"Metro\",\n",
    "        r\"agent\": r\"Agent\",\n",
    "        r\"algorithm\" : r\"\",\n",
    "        r\"algo\" : r\"\",\n",
    "        r\"\\\\toprule\": r\"\",\n",
    "        r\"global\\\\_eff\": r\"$\\\\mathcal{F}_{E}$\",\n",
    "        r\"lcs\\\\_targeted\": r\"$\\\\mathcal{F}_{R}$\",\n",
    "        r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\",\n",
    "        r\"±---\": r\"\\\\tiny{$\\\\pm0.000$}\"\n",
    "    }\n",
    "\n",
    "    with open(texfile, 'r') as f:\n",
    "        raw_content = f.read()\n",
    "\n",
    "    processed_content = raw_content\n",
    "    for orig, targ in replace_dict.items():\n",
    "        processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "\n",
    "    with open(texfile, 'w') as g:\n",
    "        g.write(processed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_write_latex(rwt_pivot, considered_agents_table, \"rw_timings.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-relnet",
   "language": "python",
   "name": "relnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}