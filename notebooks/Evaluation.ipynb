{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# # Plotting evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "# if platform.system() == 'Darwin':\n",
    "#     matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from relnet.utils.general_utils import *\n",
    "from relnet.agent.baseline.baseline_agent import *\n",
    "from relnet.agent.mcts.mcts_agent import *\n",
    "\n",
    "from relnet.evaluation.storage import EvaluationStorage\n",
    "from relnet.evaluation.experiment_conditions import *\n",
    "from relnet.evaluation.file_paths import FilePaths\n",
    "from relnet.evaluation.experiment_conditions import *\n",
    "from relnet.visualization import *\n",
    "\n",
    "\n",
    "algorithm_class = 'planning'\n",
    "\n",
    "exp_ids_prelim = ['prelim_kh_25', 'prelim_kh_50', 'prelim_kh_75']\n",
    "exp_ids_sg_synth = ['sg_uct_synth_kh_25', 'sg_uct_synth_kh_50', 'sg_uct_synth_kh_75']\n",
    "#exp_ids_sg_synth = []\n",
    "\n",
    "exp_ids_btm = ['btm_kh_25', 'btm_kh_50', 'btm_kh_75']\n",
    "exp_ids_mincost = ['mincost_kh_25', 'mincost_kh_50', 'mincost_kh_75']\n",
    "exp_ids_reduction = ['reduction_kh_25', 'reduction_kh_50', 'reduction_kh_75']\n",
    "\n",
    "exp_ids_rw = ['sg_uct_rw']\n",
    "\n",
    "storage = EvaluationStorage()\n",
    "fp = FilePaths('/experiment_data', 'aggregate', setup_directories=True)\n",
    "\n",
    "\n",
    "considered_agents_baseline = [RandomAgent,\n",
    "                       GreedyAgent,\n",
    "                       CostSensitiveGreedyAgent,\n",
    "                       LowestDegreeProductAgent,\n",
    "                       FiedlerVectorAgent,\n",
    "                       EffectiveResistanceAgent,\n",
    "                       MinCostAgent,\n",
    "                       LBHBAgent\n",
    "                             ]\n",
    "\n",
    "considered_agents_baseline_rw = [RandomAgent,\n",
    "                       LowestDegreeProductAgent,\n",
    "                       FiedlerVectorAgent,\n",
    "                       EffectiveResistanceAgent,\n",
    "                       MinCostAgent,\n",
    "                       LBHBAgent\n",
    "                             ]\n",
    "\n",
    "exp_ids_t1 = exp_ids_prelim + exp_ids_sg_synth\n",
    "exp_ids_ablation = exp_ids_btm + exp_ids_mincost + exp_ids_reduction\n",
    "\n",
    "considered_agents_t1 = [StandardMCTSAgent, SGUCTAgent]\n",
    "#considered_agents_t1 = [StandardMCTSAgent]\n",
    "considered_agents_ablation = [BTMMCTSAgent, MinCostMCTSAgent, AR80RandMCTSAgent, AR60RandMCTSAgent, AR40RandMCTSAgent,\n",
    "                             AR40DegreeMCTSAgent, AR40InvDegreeMCTSAgent, AR40LBHBMCTSAgent, AR40NumConnsMCTSAgent, \n",
    "                             AR40BestEdgeMCTSAgent, AR40BestEdgeCSMCTSAgent, AR40AvgEdgeMCTSAgent, AR40AvgEdgeCSMCTSAgent]\n",
    "\n",
    "considered_agents_rw = [StandardMCTSAgent, SGUCTAgent]\n",
    "\n",
    "considered_agents_hyps = [StandardMCTSAgent, MinCostMCTSAgent, SGUCTAgent]\n",
    "\n",
    "all_agents_t1 = considered_agents_baseline + considered_agents_t1\n",
    "all_agents_ablation = [StandardMCTSAgent] + considered_agents_ablation\n",
    "all_agents_rw = considered_agents_baseline_rw + considered_agents_rw\n",
    "\n",
    "display_order_t1 = [a.algorithm_name for a in all_agents_t1] # + ['uct_ratios']\n",
    "display_order_ablation = [a.algorithm_name for a in all_agents_ablation]\n",
    "display_order_rw = [a.algorithm_name for a in all_agents_rw]\n",
    "display_order_hyps = [a.algorithm_name for a in considered_agents_rw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_results(exp_ids):\n",
    "    all_result_dfs = []\n",
    "    for exp_id in exp_ids: \n",
    "        results = storage.get_evaluation_data(algorithm_class, exp_id)\n",
    "        experiment_details = storage.get_experiment_details(algorithm_class, exp_id)\n",
    "        # hyps = storage.retrieve_optimal_hyperparams(algorithm_class, exp_id, {}, experiment_details['experiment_conditions']['train_individually'])\n",
    "        # print(f\"optimal hyps for <<{exp_id}>> were:\")\n",
    "        # pprint.pprint(hyps)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.dropna(inplace=True)\n",
    "        all_result_dfs.append(results_df)\n",
    "\n",
    "    agg_df = pd.concat(all_result_dfs)\n",
    "    return agg_df\n",
    "\n",
    "def create_pivot(results_df, all_agents, add_mcts_ratios=False, which='synth'):\n",
    "    nondet_agents = [a.algorithm_name for a in all_agents if not a.is_deterministic]\n",
    "    pivot_idxes = {\n",
    "        'synth': ['objective_function', 'network_size'],\n",
    "        'rw_agg': ['objective_function', 'network_generator'],\n",
    "        'rw_full': ['objective_function', 'network_generator', 'graph_id']\n",
    "    }\n",
    "    \n",
    "    pivot_idx = pivot_idxes[which]\n",
    "    pivot = pd.pivot_table(results_df, values='cummulative_reward', \n",
    "                       index=pivot_idx, \n",
    "                       columns=['algorithm'],\n",
    "                       aggfunc=np.mean)\n",
    "\n",
    "    nondet_df = results_df[results_df['algorithm'].isin(nondet_agents)]\n",
    "    nondet_means_df = pd.pivot_table(nondet_df, values='cummulative_reward', \n",
    "                           columns=['algorithm', 'agent_seed'], \n",
    "                           index=pivot_idx,                       \n",
    "                           aggfunc=np.mean)\n",
    "\n",
    "    format_ci_dict = {}\n",
    "    for agent_name in nondet_agents:\n",
    "        cis = nondet_means_df[agent_name].apply(compute_ci, axis=1)\n",
    "        pivot[agent_name + \"_ci\"] = cis\n",
    "        format_ci_dict[agent_name + \"_ci\"] = (lambda x: \"±{:.3f}\".format(abs(x)))\n",
    "\n",
    "    format_ci_dict = {}\n",
    "    for agent in all_agents:\n",
    "        if agent.is_deterministic:\n",
    "            continue\n",
    "        agent_name = agent.algorithm_name\n",
    "        cis = nondet_means_df[agent_name].apply(compute_ci, axis=1)\n",
    "        pivot[agent_name + \"_ci\"] = cis\n",
    "        format_ci_dict[agent_name + \"_ci\"] = (lambda x: \"±{:.3f}\".format(abs(x)))\n",
    "        \n",
    "    if add_mcts_ratios:\n",
    "        uct_40 = AR40MCTSAgent.algorithm_name\n",
    "        uct_full = NoARMCTSAgent.algorithm_name\n",
    "        pivot['uct_ratios'] = pivot[uct_40] / pivot[uct_full]\n",
    "\n",
    "    pivot.style.format(\"{:.3f}\").format(format_ci_dict)\n",
    "    return pivot\n",
    "    \n",
    "def clean_and_write_latex(pivot_table, all_agents, cols_order, filename, transpose=True, which='results'):\n",
    "    latex_df = pivot_table.copy()\n",
    "    if which != 'hyps':\n",
    "        nondet_agents = [a.algorithm_name for a in all_agents if not a.is_deterministic]\n",
    "\n",
    "        for nondet_agent in nondet_agents:\n",
    "            colname_ci = f\"{nondet_agent}_ci\"\n",
    "            latex_df[nondet_agent] = latex_df.agg(lambda x: f\"{x[nondet_agent]:.3f}±{x[colname_ci]:.3f}\", axis=1)\n",
    "            latex_df.drop(columns=[colname_ci], inplace=True)\n",
    "\n",
    "        latex_df = latex_df[cols_order]\n",
    "        row_maxes = latex_df.max(axis=1)\n",
    "\n",
    "    repl_cols = copy(agent_display_names)\n",
    "    repl_cols = {k:v for (k,v) in repl_cols.items() if not \"UCT\" in v}\n",
    "    \n",
    "    latex_df.rename(columns=repl_cols, inplace=True)\n",
    "    latex_df.replace(objective_function_display_names, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    texfile =  str(fp.figures_dir / filename)\n",
    "    fh = open(texfile, 'w')\n",
    "    if transpose:\n",
    "        latex_df = latex_df.T\n",
    "        #t_colnames = list(latex_df.columns)\n",
    "        #table_colformat = f\"c|{''.join(['c'] * len(t_colnames)) }\"\n",
    "        #latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, column_format=table_colformat)\n",
    "        latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format)\n",
    "        fh.close()\n",
    "    else:\n",
    "        print(f\"which is {which}.\")\n",
    "        if which == 'hyps':\n",
    "            print(f\"assigning under hyps\")\n",
    "            #table_colformat = f\"lll|{''.join(['l'] * len(cols_order)) }\"\n",
    "            latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format)\n",
    "            fh.close()\n",
    "        else:\n",
    "            if which == 'rw_agg':\n",
    "                table_colformat = f\"cc|{''.join(['c'] * len(cols_order)) }\"\n",
    "            elif which in ['rw_full', 'hyps']:\n",
    "                table_colformat = f\"ccc|{''.join(['c'] * len(cols_order)) }\"\n",
    "            else:\n",
    "                raise ValueError(f\"which {which} not recognised.\")\n",
    "            latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, column_format=table_colformat)\n",
    "            fh.close()\n",
    "\n",
    "    replace_dict = {\n",
    "        r\"reduction\\\\_policy\": r\"$\\phi$\",\n",
    "        r\"sim\\\\_policy\\\\_bias\": r\"$\\\\beta$\",\n",
    "        r\"exp\\\\_name\": r\"Experiment\",\n",
    "        r\"synth\\\\_25\": r\"KH-25\",\n",
    "        r\"synth\\\\_50\": r\"KH-50\",\n",
    "        r\"synth\\\\_75\": r\"KH-75\",\n",
    "        r\"rw\\\\_internet\\\\_topology\": r\"Internet\",\n",
    "        r\"rw\\\\_metro\": r\"Metro\",        \n",
    "        r\"rw\": \"Real-world\",\n",
    "        \n",
    "        r\"C\\\\_p\": r\"$C_p$\",\n",
    "        \n",
    "        r\"uct\\\\_btm\": r\"SG-UCT\\\\textsubscript{BTM}\",\n",
    "        r\"uct\\\\_mincost\": r\"SG-UCT\\\\textsubscript{MINCOST}\",\n",
    "\n",
    "        r\"uct\\\\_rand\\\\_80\": r\"SG-UCT\\\\textsubscript{RAND-80}\",\n",
    "        r\"uct\\\\_rand\\\\_60\": r\"SG-UCT\\\\textsubscript{RAND-60}\",\n",
    "        r\"uct\\\\_rand\\\\_40\": r\"SG-UCT\\\\textsubscript{RAND-40}\",        \n",
    "        \n",
    "        r\"uct\\\\_deg\\\\_40\": r\"SG-UCT\\\\textsubscript{DEG-40}\",\n",
    "        r\"uct\\\\_invdeg\\\\_40\": r\"SG-UCT\\\\textsubscript{INVDEG-40}\",\n",
    "        r\"uct\\\\_lbhb\\\\_40\": r\"SG-UCT\\\\textsubscript{LBHB-40}\",\n",
    "        r\"uct\\\\_numconns\\\\_40\": r\"SG-UCT\\\\textsubscript{NC-40}\",\n",
    "        r\"uct\\\\_be\\\\_40\": r\"SG-UCT\\\\textsubscript{BE-40}\",        \n",
    "        r\"uct\\\\_becs\\\\_40\": r\"SG-UCT\\\\textsubscript{BECS-40}\",\n",
    "        r\"uct\\\\_ae\\\\_40\": r\"SG-UCT\\\\textsubscript{AE-40}\",\n",
    "        r\"uct\\\\_aecs\\\\_40\": r\"SG-UCT\\\\textsubscript{AECS-40}\",        \n",
    "\n",
    "        r\"sg\\\\_uct\": r\"SG-UCT\",        \n",
    "        r\"uct\": r\"UCT\",\n",
    "        \n",
    "        r\"greedy\\\\_cs\": r\"Greedy\\\\textsubscript{CS}\",\n",
    "        \n",
    "        r\"avg\\\\_edge\\\\_cs\": r\"AECS-40\",\n",
    "        \n",
    "        r\"uct\\\\_ratios\": r\"UCT\\\\textsubscript{40} / UCT\",\n",
    "        \n",
    "        r\"internet\\\\_topology\": \"Internet\",\n",
    "        r\"metro\": \"Metro\",\n",
    "        r\"graph\\\\_id\": \"Graph\",\n",
    "        \n",
    "        r\"nan±nan\": r\"---\",\n",
    "        r\"NaN\": r\"---\",\n",
    "        r\"nan\": r\"---\",\n",
    "        r\"objective\\\\_function\": r\"Objective\",\n",
    "        r\"network\\\\_size\" : r\"$|V|$\",\n",
    "        r\"network\\\\_generator\" : r\"$\\\\mathbf{G}$\",\n",
    "        r\"kaiser\\\\_hilgetag\": r\"KH\",\n",
    "        r\"internet\\\\_topology\": r\"Internet\",\n",
    "        r\"metro\": r\"Metro\",\n",
    "        r\"agent\": r\"Agent\",\n",
    "        r\"algorithm\" : r\"\",\n",
    "        r\"global\\\\_eff\": r\"$\\\\mathcal{F}_{E}$\",\n",
    "        r\"lcs\\\\_targeted\": r\"$\\\\mathcal{F}_{R}$\",\n",
    "        r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\",\n",
    "        r\"±---\": r\"\\\\tiny{$\\\\pm0.000$}\"\n",
    "    }\n",
    "\n",
    "    with open(texfile, 'r') as f:\n",
    "        raw_content = f.read()\n",
    "\n",
    "    processed_content = raw_content\n",
    "    for orig, targ in replace_dict.items():\n",
    "        processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "\n",
    "    with open(texfile, 'w') as g:\n",
    "        g.write(processed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment 1: Preliminary Results + SG-UCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t1_results = fetch_results(exp_ids_t1)\n",
    "t1_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot = create_pivot(t1_results, all_agents_t1, add_mcts_ratios=False, which='synth')\n",
    "clean_and_write_latex(pivot, all_agents_t1, display_order_t1, f't1_results.tex', which='synth')\n",
    "pivot.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment 2: Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ablation_results = fetch_results(exp_ids_ablation)\n",
    "ablation_results = pd.concat([ablation_results, t1_results[t1_results['algorithm'] == StandardMCTSAgent.algorithm_name]])\n",
    "ablation_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot = create_pivot(ablation_results, all_agents_ablation, which='synth')\n",
    "clean_and_write_latex(pivot, all_agents_ablation, display_order_ablation, 'ablation_results.tex', which='synth')\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Figure: mincost policy bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyperparam_dfs = {}\n",
    "agent_name = MinCostMCTSAgent.algorithm_name\n",
    "\n",
    "for experiment_id in exp_ids_mincost:\n",
    "    param_spaces, df = storage.get_hyperparameter_optimisation_data(algorithm_class, experiment_id, {}, train_individually=False)\n",
    "\n",
    "    latest_experiment = storage.get_experiment_details(algorithm_class, experiment_id)\n",
    "    objective_functions = latest_experiment[\"objective_functions\"]\n",
    "    num_nodes = latest_experiment['experiment_conditions']['base_n']\n",
    "\n",
    "    expanded_data = []\n",
    "    for objective_function in objective_functions:\n",
    "        subset = df[(df['agent_name'] == agent_name) & (df['objective_function'] == objective_function)]\n",
    "        subset.drop(columns=['agent_name'])\n",
    "\n",
    "        for idx, row in subset.iterrows():\n",
    "            row_copy = dict(row)\n",
    "            hyperparams_id = row['hyperparams_id']\n",
    "            hyperparams = param_spaces[objective_function][agent_name][hyperparams_id]\n",
    "            row_copy.update(hyperparams)\n",
    "            expanded_data.append(row_copy)\n",
    "\n",
    "        hyp_df = pd.DataFrame(expanded_data).drop(columns=['hyperparams_id', 'graph_id', 'network_generator'])\n",
    "        hyp_df['N'] = [str(num_nodes)] * len(hyp_df)\n",
    "        hyp_df = hyp_df.rename(columns={\"sim_policy_bias\": r\"$\\beta$\", \"avg_reward\": \"Mean Reward\"})\n",
    "        \n",
    "        if objective_function not in hyperparam_dfs:\n",
    "            hyperparam_dfs[objective_function] = []\n",
    "        \n",
    "        hyperparam_dfs[objective_function].append(hyp_df)\n",
    "\n",
    "fig_title = 'mincost_beta.pdf'        \n",
    "figure_save_path = fp.figures_dir / fig_title\n",
    "plot_beta_param(hyperparam_dfs, figure_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table: Real-World Graph Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rw_results = fetch_results(exp_ids_rw)\n",
    "rw_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot = create_pivot(rw_results, all_agents_rw, which='rw_full')\n",
    "clean_and_write_latex(pivot, all_agents_rw, display_order_rw, 'rw_results_full.tex', transpose=False, which='rw_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot = create_pivot(rw_results, all_agents_rw, which='rw_agg')\n",
    "clean_and_write_latex(pivot, all_agents_rw, display_order_rw, 'rw_results_agg.tex', transpose=False, which='rw_agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table: Hyperparameters Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_exps = exp_ids_t1 + exp_ids_mincost + exp_ids_rw\n",
    "\n",
    "relevant_hyps = ['C_p', 'sim_policy_bias', 'reduction_policy']\n",
    "exp_id_to_name = {('prelim_kh_25', 'kaiser_hilgetag'): 'synth_25',\n",
    "                  ('prelim_kh_50', 'kaiser_hilgetag'): 'synth_50',\n",
    "                  ('prelim_kh_75', 'kaiser_hilgetag'): 'synth_75',\n",
    "                  \n",
    "                  ('mincost_kh_25', 'kaiser_hilgetag'): 'synth_25',\n",
    "                  ('mincost_kh_50', 'kaiser_hilgetag'): 'synth_50',\n",
    "                  ('mincost_kh_75', 'kaiser_hilgetag'): 'synth_75',\n",
    "                  \n",
    "                  ('sg_uct_synth_kh_25', 'kaiser_hilgetag'): 'synth_25',\n",
    "                  ('sg_uct_synth_kh_50', 'kaiser_hilgetag'): 'synth_50',\n",
    "                  ('sg_uct_synth_kh_75', 'kaiser_hilgetag'): 'synth_75',\n",
    "                  \n",
    "                  ('sg_uct_rw', 'internet_topology'): 'rw_internet_topology',\n",
    "                  ('sg_uct_rw', 'metro'): 'rw_metro'\n",
    "                 }\n",
    "\n",
    "bootstrap_id_map = {\n",
    "      'mincost_kh_25': 'prelim_kh_25',\n",
    "      'mincost_kh_50': 'prelim_kh_50',\n",
    "      'mincost_kh_75': 'prelim_kh_75',\n",
    "    \n",
    "}\n",
    "\n",
    "hyps_rows = []\n",
    "\n",
    "\n",
    "for exp_id in all_exps: \n",
    "    print(exp_id)\n",
    "    experiment_details = storage.get_experiment_details(algorithm_class, exp_id)\n",
    "    gens = experiment_details['network_generators']\n",
    "    objs = experiment_details['objective_functions']\n",
    "    is_individual = experiment_details['experiment_conditions']['train_individually']\n",
    "    hyps = storage.retrieve_optimal_hyperparams(algorithm_class, exp_id, {}, is_individual)\n",
    "    print(hyps)\n",
    "\n",
    "    for gen in gens:\n",
    "        for obj in objs:\n",
    "            for agent in considered_agents_hyps:\n",
    "                if not is_individual:\n",
    "                    if (gen, obj, agent.algorithm_name) in hyps:\n",
    "                        hyps_vals = hyps[(gen, obj, agent.algorithm_name)][0]\n",
    "\n",
    "                        entry = {}\n",
    "                        entry['exp_name'] = exp_id_to_name[(exp_id, gen)]\n",
    "                        entry['objective_function'] = obj\n",
    "                        entry['agent'] = agent.algorithm_name\n",
    "                        entry['graph_id'] = '---'\n",
    "\n",
    "                        for hyp_name in relevant_hyps:\n",
    "                            if hyp_name == 'C_p' and agent.algorithm_name == MinCostMCTSAgent.algorithm_name:\n",
    "                                boostrapped_hyps = storage.retrieve_optimal_hyperparams(algorithm_class, bootstrap_id_map[exp_id], {}, experiment_details['experiment_conditions']['train_individually'])\n",
    "                                entry[hyp_name] = str(boostrapped_hyps[(gen, obj, StandardMCTSAgent.algorithm_name)][0][hyp_name])\n",
    "                                print(f\"woo, entry is {hyp_name, entry[hyp_name]}\")\n",
    "                            else:\n",
    "                                if hyp_name in hyps_vals:\n",
    "                                    entry[hyp_name] = str(hyps_vals[hyp_name])\n",
    "                                else:\n",
    "                                    if agent.algorithm_name == SGUCTAgent.algorithm_name and hyp_name == 'sim_policy_bias':\n",
    "                                        # specified as default parameter for SG-UCT\n",
    "                                        entry[hyp_name] = str(25)\n",
    "                                    else:\n",
    "                                        entry[hyp_name] = '---'\n",
    "                        hyps_rows.append(entry)\n",
    "                else:\n",
    "                    gen_class = retrieve_generator_class(gen)\n",
    "                    gids = get_graph_ids_to_iterate(is_individual, gen_class, fp)\n",
    "                    print(f\"gids were {gids}\")\n",
    "                    for gid in gids:\n",
    "                        if (gen, obj, agent.algorithm_name, gid) in hyps:\n",
    "                            hyps_vals = hyps[(gen, obj, agent.algorithm_name, gid)][0]\n",
    "                            print(hyps_vals)\n",
    "                            entry = {}\n",
    "                            entry['exp_name'] = exp_id_to_name[(exp_id, gen)]\n",
    "                            entry['objective_function'] = obj\n",
    "                            entry['agent'] = agent.algorithm_name\n",
    "                            entry['graph_id'] = gid\n",
    "                            for hyp_name in relevant_hyps:\n",
    "                                if hyp_name in hyps_vals:\n",
    "                                    entry[hyp_name] = str(hyps_vals[hyp_name])\n",
    "                                else:\n",
    "                                    if agent.algorithm_name == SGUCTAgent.algorithm_name and hyp_name == 'sim_policy_bias':\n",
    "                                        # specified as default parameter for SG-UCT\n",
    "                                        entry[hyp_name] = str(25)\n",
    "                                    else:\n",
    "                                        entry[hyp_name] = '---'\n",
    "\n",
    "                            hyps_rows.append(entry)\n",
    "\n",
    "                    \n",
    "                        \n",
    "hyps_df = pd.DataFrame(hyps_rows)\n",
    "hyps_df.head(25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(hyps_df, values=relevant_hyps,\n",
    "                   index= ['exp_name', 'graph_id', 'agent'],\n",
    "                   columns=['objective_function'],\n",
    "                   aggfunc='first')\n",
    "pivot\n",
    "clean_and_write_latex(pivot, considered_agents_hyps, display_order_hyps, 'hyps.tex', transpose=False, which='hyps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}